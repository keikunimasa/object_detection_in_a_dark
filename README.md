# ğŸŒŒ Dark Environment Object Detection ğŸ“¸

## Purpose
Image analysis and object detection technologies play a critical role, particularly in applications such as automotive contexts. However, sensors and recognition systems often struggle in scenarios with limited visibility, such as rainy weather or darkness. This project seeks to demonstrate the capability of CNNs to accurately detect objects in images taken under low light conditions or with artificially added noise.

The study aims to advance image analysis and object detection technologies by focusing on improving accuracy in challenging environments characterized by darkness and noise distortion. Leveraging deep learning techniques, specifically CNNs, the research proposes methods to achieve robust object detection performance even in images affected by low visibility or noise.

## Target
This study primarily focuses on images captured in dark environments, aiming to enhance object detection performance under conditions of reduced visibility.
## Dark Image Exaples

### Cat-classğŸˆ
<img width="400" alt="image" src="https://github.com/keikunimasa/object_detection_in_a_dark/assets/100010521/f3e85c71-1861-4b88-a8ef-8e8083318c85">
<img width="300" alt="image" src="https://github.com/keikunimasa/object_detection_in_a_dark/assets/100010521/2987a47b-3a97-4f6a-8233-5a4e4b01c23f">
<img width="300" alt="image" src="https://github.com/keikunimasa/object_detection_in_a_dark/assets/100010521/e4ca4bc1-fe99-46a5-9365-0f9a943e01f3">


### Dog-classğŸ•
<img width="300" alt="image" src="https://github.com/keikunimasa/object_detection_in_a_dark/assets/100010521/03a3e720-38f6-4526-aa84-cd0078bac644">
<img width="300" alt="image" src="https://github.com/keikunimasa/object_detection_in_a_dark/assets/100010521/f995a754-5654-4c5f-a4b6-e3f7c6ab0366">


### Car-classğŸš—
<img width="359" alt="image" src="https://github.com/keikunimasa/object_detection_in_a_dark/assets/100010521/ac99c3b5-9f6e-457a-9030-f8a738a8dbe5">


## References
This research builds upon the following foundational literature:

- Research Paper: "Revealing 'Invisible' Objects in Darkness Using Deep Learning" (January 31, 2019, AI Scholar Tech)
- Qiita Article: "Handling Dark Environment Object Detection" (TrashBoxx, Qiita)

## Datasets
This study utilizes the following datasets:

- **Cifar10**: A dataset containing images of 10 common object categories, widely used for image classification and object detection tasks.
- **CBIU2019**: A dataset specialized in images captured in dark environments, suitable for research on object recognition under low light conditions.

### Theorem: Reasons for Inference Failure on Dark Images and Hypotheses in This Field
- As shown in the above image, the distribution is concentrated near zero across all channels.
- The above graph also confirms that pixel values above 150 are missing.
- Due to these effects, Shannon entropy and features input into machine learning are likely to be significantly reduced.

## Ensuring Darkness in Images Processed to Mimic a Dark Distribution
Dark images were generated based on the two points above.
- By applying a process that results in a distribution similar to the above graph to any image, qualitatively dark images should be obtained.
- Such processing was performed within a Notebook, and the model's performance was evaluated using images filtered with darkness, as shown below.

## Implementation Strategy
In this study, we outline the following strategies to achieve object detection in dark environments:

1. **Dataset Selection**: Utilize Cifar10 and CBIU2019 datasets to prepare for a variety of scenarios.
   
2. **Target Object Categories and Evaluation**: Focus on common categories across Cifar10 and CBIU, specifically evaluating potential accuracy challenges for categories like cars and ships under low visibility conditions.

3. **Approaches for Dark Environment Object Detection**:
   - Implement object detection using pre-trained models on Cifar10.
   - Fine-tune ResNet50 on the CBIU dataset to specialize in detecting objects in darkness.
   - Explore preprocessing techniques such as edge detection algorithms to enhance model performance.

By exploring and comparing these approaches, we aim to innovate object detection technology in dark environments.

> # **Summary of Outcomes**

## **Proof of Concepts**
It was confirmed that models become unstable with images under dark conditions by attempts below.

### Dark-Image Classification Accuracy by Cifar10 Ã— ResNet50ã€€# Attemopt-1( lr=0.002, momentum=0.8 )

<img width="250" alt="image" src="https://github.com/keikunimasa/object_detection_in_a_dark/assets/100010521/c20233cf-8bb0-4a5b-a516-684ac396ac4b">
<img width="250" alt="image" src="https://github.com/keikunimasa/object_detection_in_a_dark/assets/100010521/9107edbe-490b-4962-a5ed-b31d6644a45b">

### Dark-Image Classification Accuracy by Cifar10 Ã— ResNet50ã€€# Attemopt-2( lr=0.003, momentum=0.9 )

<img width="250" alt="image" src="https://github.com/keikunimasa/object_detection_in_a_dark/assets/100010521/55654aea-6035-4c12-90e4-fe36cf7cb20e">

## Classification Results :
* Under conditions, it is **almost impossible** to make predictions using models based on regular images.
* For images with particularly distinguishable features, such as dogs, it seems that predictions can be made even in darkness.
* There is a possibility that ships belong to a different class from those in CIFAR-10.

## Conclusion on Training and Classification with CIFAR-10:
* Comparing to Attempt-1, classes like Dog had low accuracy, while Cat and Ship achieved over 20% accuracy.
* Predictions became **unstable** due to dark noise.
* Even for easily distinguishable classes like Dog, the impact of noise was significant.

# Implementing Classification Models for Dark-Images 
### Attempt-3: pre-trained ResNet50 and learn DarkImages( lr=0.003, momentum=0.8 )
Results with Over fitting.

<img width="250" alt="image" src="https://github.com/keikunimasa/object_detection_in_a_dark/assets/100010521/38916b79-e0f8-464f-9729-f190cf9f52fb">
<img width="250" alt="image" src="https://github.com/keikunimasa/object_detection_in_a_dark/assets/100010521/167b541d-ea6d-4539-b066-425fdb77c554">

* Even when training with dark images, the noise prevents **proper learning**.
* There is a possibility that the model is unable to detect features.
* As this is fine-tuning of a pre-trained model, **it may be influenced by previous training**.

> Next attempt: I will verify by building the model without fine-tuning as follows.

### Attempt-4: First-Scratch Model for Dark-Images
Results with low accuracy...

<img width="250" alt="image" src="https://github.com/keikunimasa/object_detection_in_a_dark/assets/100010521/e2121175-9fd0-4513-b382-1125a17444e6">



> # Sttrugled Some Attempts...
Please read .ipynb fileâœ¨

## âœ¨ Finally Made Very-Longed Models âœ¨
<Epoch 0 to 12>
<img width="250" alt="image" src="https://github.com/keikunimasa/object_detection_in_a_dark/assets/100010521/d0d02b3e-7ad7-4cf8-a7da-e6332d2a9bcd">
<epoch 18 to 36>
<img width="250" alt="image" src="https://github.com/keikunimasa/object_detection_in_a_dark/assets/100010521/2d8b6770-a332-446f-b50a-da78f7204cde">
<Classificaiton Accuracy>
<img width="250" alt="image" src="https://github.com/keikunimasa/object_detection_in_a_dark/assets/100010521/7835d3e1-fbff-4ab5-a3de-efdaa28b8ee7">


## Summary of Training Results 
After 36 epochs of training, an average accuracy of 82% to 88% was achieved across all classes.

1. Accuracy varied by class, with **cars** and **dogs** being correctly identified with 95% to 100% accuracy. 
2. **However**, ships had a low accuracy of 56%, and cats had an accuracy of 80%. 
3. For the car class, features like headlights might make identification easier.

> Predicting images of ships in darkness remains challenging under the given conditions and is a potential subject for further research. The research **hypotheses** for this issue are as follows:

> For **ship** images, 
> 1. **random reflections of light** on the water may act as noise.
> 2. **Multiple ships** in an image increase the amount of "Entropy" during training, 
>    * possibly leading to insufficient iterations
>    * number of image data.

### Significant Accuracy Improvement Achieved Through Cross-Validation and Data Augmentation
- The K-Fold cross-validation method was used.  
- The data includes various types of information beyond class labels, enabling learning in diverse scenarios.  
- By applying various transformations such as color adjustments, rotation, scaling, cropping, and color tone changes, the model's generalization performance was improved, achieving high accuracy on validation data.  

The graph of the training results is shown below.

<img width="400" alt="image" src="https://github.com/user-attachments/assets/96fd6300-ec5c-4c50-b59d-d4b47130ff82">
<img width="400" alt="image" src="https://github.com/user-attachments/assets/1c4c8acd-b41c-43b1-8494-1966c748afa7">

# Important Open Questions âœ¨
1. Developing methods with **high generalizability** to data with images which has large "Entropy".
2. Proposing models that can handle **random and strong noise without pre-processing** the data.

Especially, addressing the first issue could solve challenges in **noisy environments like MRI images**. 
These issues are open questions, and discussions and pull requests are welcome.

## **Current Solutions and Ideas**ğŸ¤”
The proposed solutions are:
1. Implementing gates that separates object detection and classification.
2. Applying a **noise reduction filter** during pre-processing.
3. Use other known models or device instead such as:
   * **DenseNet**
   * Yolo
   * Quanta Image Sensor
However, the author has not yet addressed these solutions.  


# ğŸŒŒ æš—é—‡ã«ãŠã‘ã‚‹ç‰©ä½“æ¤œçŸ¥ ğŸ“¸

## ç ”ç©¶ç›®çš„
æœ¬ç ”ç©¶ã®ç›®çš„ã¯ã€ç”»åƒè§£æãŠã‚ˆã³ç‰©ä½“æ¤œçŸ¥æŠ€è¡“ã®é€²å±•ã«è²¢çŒ®ã™ã‚‹ã“ã¨ã§ã™ã€‚å…·ä½“çš„ã«ã¯ã€å¾“æ¥ã®æ–¹æ³•ã§ã¯å›°é›£ã§ã‚ã£ãŸæš—é—‡ã‚„ãƒã‚¤ã‚ºãŒåŠ ã‚ã£ãŸç’°å¢ƒä¸‹ã§ã®ç‰©ä½“æ¤œå‡ºç²¾åº¦ã®å‘ä¸Šã‚’å®Ÿç¾ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¦ã„ã¾ã™ã€‚æ·±å±¤å­¦ç¿’ï¼ˆCNNï¼‰ã‚’æ´»ç”¨ã—ã€æš—é—‡ã§ã®æ’®å½±ã‚„ãƒã‚¤ã‚ºå‡¦ç†ã•ã‚ŒãŸç”»åƒã«ãŠã„ã¦ã‚‚ã€ä¿¡é ¼æ€§ã®é«˜ã„ç‰©ä½“æ¤œçŸ¥ã‚’å®Ÿç¾ã™ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã—ã¾ã™ã€‚

## ç ”ç©¶å¯¾è±¡
æœ¬ç ”ç©¶ã§ã¯ã€ä¸»ã«æš—é—‡ã§æ’®å½±ã•ã‚ŒãŸç”»åƒã‚’å¯¾è±¡ã¨ã—ã¾ã™ã€‚å…·ä½“çš„ã«ã¯ã€ä½è¦–èªæ€§ç’°å¢ƒä¸‹ã§ã®ç‰©ä½“æ¤œå‡ºã®èª²é¡Œã«ç„¦ç‚¹ã‚’å½“ã¦ã€ãã®è§£æ±ºç­–ã‚’æ¨¡ç´¢ã—ã¾ã™ã€‚

## é–¢é€£æ–‡çŒ®
æœ¬ç ”ç©¶ã®åŸºç›¤ã¨ãªã‚‹æ–‡çŒ®ã¨ã—ã¦ã€ä»¥ä¸‹ã®æƒ…å ±æºã‚’å‚è€ƒã«ã—ã¾ã—ãŸã€‚

- ç ”ç©¶è«–æ–‡: ã€Œãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’ç”¨ã„ã¦æš—é—‡ã®ä¸­ã§ã€Œè¦‹ãˆãªã„ã€ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’æ˜ã‚‰ã‹ã«ã™ã‚‹ã€ï¼ˆ2019å¹´1æœˆ31æ—¥ã€AI Scholar Techï¼‰

- Qiita è¨˜äº‹: ã€Œæš—é—‡ã§ã®ç‰©ä½“æ¤œçŸ¥ã®ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã€ï¼ˆTrashBoxxæ°ã€Qiitaï¼‰

- å‚è€ƒè¬›ç¾©ï¼ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ¼”ç¿’: ä¸»ã«ã‚»ã‚¯ã‚·ãƒ§ãƒ³9ãŠã‚ˆã³10ã§è¡Œã‚ã‚ŒãŸå†…å®¹ã‚’å‚ç…§ã—ã¾ã—ãŸã€‚

## ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
ã“ã®ç ”ç©¶ã§ã¯ã€ä»¥ä¸‹ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚

- **Cifar10**: 10ç¨®é¡ã®ä¸€èˆ¬çš„ãªç‰©ä½“ã‚’å«ã‚€ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€‚ç”»åƒã®åˆ†é¡ãŠã‚ˆã³ç‰©ä½“æ¤œå‡ºã«åºƒãä½¿ç”¨ã•ã‚Œã¦ã„ã¾ã™ã€‚

- **CBIU2019**: æš—é—‡ã§æ’®å½±ã•ã‚ŒãŸç”»åƒã«ç‰¹åŒ–ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€‚ä½ç…§åº¦æ¡ä»¶ä¸‹ã§ã®ç‰©ä½“èªè­˜ã®ç ”ç©¶ã«é©ã—ã¦ã„ã¾ã™ã€‚

## å®Ÿè£…è¨ˆç”»
æœ¬ç ”ç©¶ã§ã¯ã€ä»¥ä¸‹ã®æ‰‹æ³•ã‚’ç”¨ã„ã¦æš—é—‡ã§ã®ç‰©ä½“æ¤œçŸ¥ã®å®Ÿç¾ã‚’ç›®æŒ‡ã—ã¾ã™ã€‚

1. **ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®é¸å®š**: Cifar10ãŠã‚ˆã³CBIU2019ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’åˆ©ç”¨ã—ã€å¤šæ§˜ãªã‚·ãƒãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã«å¯¾å¿œã™ã‚‹ãŸã‚ã®æº–å‚™ã‚’è¡Œã„ã¾ã™ã€‚

2. **å¯¾è±¡ç‰©ä½“ã‚«ãƒ†ã‚´ãƒªã®é¸å®šã¨è©•ä¾¡**: Cifar10ã¨CBIUã§å…±é€šã™ã‚‹ã‚«ãƒ†ã‚´ãƒª [çŒ«ã€çŠ¬ã€è»Šï¼ˆautomobileï¼‰ã€èˆ¹ï¼ˆboatï¼‰] ã‚’é¸ã³ã€ç‰¹ã«è»Šã¨èˆ¹ã«ã¤ã„ã¦ã¯ç²¾åº¦ä½ä¸‹ã®ãƒªã‚¹ã‚¯ã‚’è€ƒæ…®ã—ãŸè©•ä¾¡ã‚’è¡Œã„ã¾ã™ã€‚

3. **æš—é—‡ã§ã®ç‰©ä½“æ¤œçŸ¥æ‰‹æ³•ã®é¸å®šã¨å®Ÿè£…**:
   - Cifar10ã§äº‹å‰å­¦ç¿’ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’ãƒ™ãƒ¼ã‚¹ã«ã—ãŸç‰©ä½“æ¤œçŸ¥ã®å®Ÿè£…
   - CBIUãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ResNet50ã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã€æš—é—‡ã§ã®ç‰¹å®šç‰©ä½“æ¤œçŸ¥ã«ç‰¹åŒ–ã—ãŸãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰
   - ç”»åƒã®ã‚¨ãƒƒã‚¸æ¤œå‡ºã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ç”¨ã„ãŸäº‹å‰å‡¦ç†ã‚’è¡Œã„ã€ãã®å¾Œã®å­¦ç¿’ã«æ´»ç”¨ã™ã‚‹æ‰‹æ³•ã®æ¤œè¨

ã“ã‚Œã‚‰ã®æ‰‹æ³•ã‚’è©³ç´°ã«æ¤œè¨ã—ã€å®Ÿè£…ãƒ»è©•ä¾¡ã‚’é€²ã‚ã‚‹ã“ã¨ã§ã€æš—é—‡ã§ã®ç‰©ä½“æ¤œçŸ¥æŠ€è¡“ã®é©æ–°ã‚’ç›®æŒ‡ã—ã¾ã™ã€‚
